<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Export news from google sites</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            color: #333333;
        }

        header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 20px;
            border-bottom: 1px solid #dddddd;
        }

        header h1 {
            font-size: 24px;
            margin: 0;
        }

        header a {
            text-decoration: none;
            color: #666666;
        }

        .content {
            max-width: 750px;
            margin: 40px auto;
            padding: 20px;
        }

        .content h2 {
            font-size: 34px;
            margin-top: 0;
        }

        .content h3 {
            font-size: 20px;
            margin-top: 30px;
        }

        .content p {
            margin: 0;
            padding: 10px 0;
        }

        .content a {
            color: #2b7bb9;
            text-decoration: none;
        }

        .content pre {
            background-color: #f5f5f5;
            padding: 10px;
            border-left: 3px solid #cccccc;
            overflow-x: auto;
            white-space: pre-wrap;
        }

        .date {
            color: #888888;
            font-size: 14px;
            margin-bottom: 20px;
        }

        .author {
            color: #888888;
            font-size: 14px;
            margin-bottom: 40px;
        }
    </style>
</head>

<body>
    <header>
        <h1>Polibyte</h1>
        <nav>
            <a href="#">About Me</a>
        </nav>
    </header>
    <div class="content">
        <div class="date">Apr 27, 2012</div>
        <div class="author">1 minute read</div>
        <h2>Export news from google sites</h2>
        <p>Iâve added a script, <a href="#">export_google_site_news</a>, to my catchall repository on github.</p>
        <p>For example, to download the news stories at 
            <a href="#">https://sites.google.com/a/medinacommunityband.org/www/announcements</a>, you would run
        </p>
        <pre>
export_google_site_news https://sites.google.com/a/medinacommunityband.org/www announcements
        </pre>
        <h3>The backstory</h3>
        <p>When Free It Athens moved our website from Google Sites to Drupal, we 
            started from scratch rather than importing our old content. I realized 
            on Wednesday that the news
            posts on the site were interesting historical information, yet Iâd never archived them.
        </p>
        <p>First, I tried a recursive wget.</p>
        <pre>
wget -r --no-parent --no-clobber ""
        </pre>
        <p>This failed to work because Google pointlessly used javascript rather than 
            anchor tags to link between the news listing pages.
        </p>
        <p>Next I found and tried to use the google-sites-export tool from 
            Googleâs Data Liberation Team, but I was never able to authenticate 
            succesfully from it.
        </p>
        <p>At this point I was worried Iâd need to use a tool like Selenium to run the 
            javascript, but then I realized the news listing pages took a single 
            paramater to determine how far along in the pagination they were. 
            It wouldnât take more than a C-style for loop to download them all.
        </p>
        <pre>
for i in $(seq 0 10 120); do
    wget ""     "--Onews.$i"
done
        </pre>
        <p>After doing that, I looked at the first one and determined a pattern 
            that would match the relative URLs of individual news stories. 
            I then extracted all the URLs.
        </p>
        <pre>
grep -E -h -o '/a/freeitathens.org/foo/news/[a-z0-9\-_]+' news.* | 
sort -u > news_links
        </pre>
        <p>Once I had the list of URLs, it was simple to have wget download them all.</p>
        <pre>
wget -i news_links -B https://sites.google.com
        </pre>
        <p>Since I didnât find any other guides to doing this, I decided to 
            flesh out what Iâd done into a simple tool and write about it here.
        </p>
    </div>
</body>

</html>