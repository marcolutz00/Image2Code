<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Export News</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            color: #333;
            margin: 0;
            padding: 20px;
            background-color: #f9f9f9;
        }
        header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 40px;
        }
        header h1 {
            font-size: 24px;
            font-weight: 700;
            margin: 0;
        }
        header a {
            font-size: 14px;
            text-decoration: none;
            color: #333;
        }
        h2 {
            font-size: 36px;
            font-weight: 700;
            margin-bottom: 10px;
        }
        .date {
            font-size: 16px;
            color: #777;
            margin-bottom: 5px;
        }
        .read-time {
            font-size: 14px;
            color: #777;
            margin-bottom: 20px;
        }
        p {
            line-height: 1.6;
            margin-bottom: 20px;
        }
        a {
            color: #0066cc;
            text-decoration: none;
        }
        pre {
            background-color: #e6e6e6;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
            margin-bottom: 20px;
        }
        img {
            width: 100%;
            max-width: 400px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <header>
        <h1>Polibyte</h1>
        <a href="#">More Info</a>
    </header>
    
    <h2>Export news from google sites</h2>
    <div class="date">Apr 27, 2012</div>
    <div class="read-time">One min of reading</div>

    <p>I've put online a quick code snippet, <a href="#">export_google_site_news</a>, to my main repository located on github.</p>
    <p>To illustrate, for pulling the news posts from https://sites.google.com/a/medinacommunityband.org/www/announcements, you can call:</p>
    
    <pre>
export_google_site_news \
https://sites.google.com/a/medinacommunityband.org/www \
announcements
    </pre>
    
    <h3>Genesis of This</h3>
    
    <p>When Free It Athens migrated their site away from Google Sites over to Drupal, they went fresh, losing all the previous content. I just realized that news data on the old site was valuable historical content, and I hadn’t saved it.</p>
    
    <p>Initially, I gave recursive wget a whirl.</p>
    
    <pre>
wget -r --no-parent --no-clobber \
""
    </pre>
    
    <p>This just flat failed as Google made the mistake of using javascript rather than anchor tags to connect news pages.</p>
    
    <p>I hunted down and tried Google’s own google-sites-export from their Data Liberation Team, but could never authenticate correctly.</p>
    
    <p>I then feared I’d need Selenium to trigger the javascript, but then realized that the news pages took a single parameter to determine which paginated results to display. Looping would get them all.</p>
    
    <pre>
for i in $(seq 0 10 120); do 
  wget "" \
  "-Onews.$i"
done
    </pre>

    <p>After getting the first one, I saw a pattern to match each news stories' relative paths. Then extracted out all those paths.</p>

    <pre>
grep -E -h -o "/a/freeitathens.org/foo/news/[a-z0-9\-]+" news.* | 
sort -u > news_links
    </pre>

    <p>Once I had all the paths, it was easy to get wget to fetch them all.</p>

    <pre>
wget -i news_links -B https://sites.google.com
    </pre>

    <p>Since I found zero guides online, I tried writing up a simple script from the above, and am detailing it here.</p>

</body>
</html>