<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Export News from Google Sites</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            color: #333;
            background-color: #f9f9f9;
            padding: 20px;
            line-height: 1.6;
        }
        h1 {
            font-weight: bold;
            font-size: 32px;
            margin-bottom: 20px;
        }
        h2 {
            font-weight: bold;
            font-size: 24px;
            margin: 30px 0 10px;
        }
        p, a {
            font-size: 16px;
            line-height: 1.4;
        }
        a {
            color: #0066cc;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 30px;
        }
        .date, .reading-time {
            font-style: italic;
            color: #666;
        }
        .code-block {
            background-color: #f5f5f5;
            padding: 15px;
            border: 1px solid #ddd;
            margin: 20px 0;
            font-family: monospace;
            white-space: pre-wrap;
        }
    </style>
</head>
<body>
    <div class="header">
        <span>Polibyte</span>
        <a href="#">More Info</a>
    </div>

    <h1>Export news from google sites</h1>

    <div class="date">Apr 27, 2012</div>
    <div class="reading-time">One min of reading</div>

    <p>
        I've put online a quick code snippet, <a href="#">export_google_site_news</a>, to my main repository located on github.
    </p>

    <p>
        To illustrate, for pulling the news posts from 
        https://sites.google.com/a/medinacommunityband.org/www/announcements, you can call:
    </p>

    <div class="code-block">
        export_google_site_news \<br>
        https://sites.google.com/a/medinacommunityband.org/www \<br>
        announcements
    </div>

    <h2>Genesis of This</h2>

    <p>
        When Free It Athens migrated their site away from Google Sites over to Drupal, they went
        fresh, losing all the previous content. I just realized that news data on the old site was valuable
        historical content, and I hadn't saved it.
    </p>

    <p>
        Initially, I gave recursive wget a whirl.
    </p>

    <div class="code-block">
        wget -r --no-parent --no-clobber \<br>
        ""
    </div>

    <p>
        This just failed as Google made the mistake of using javascript rather than anchor tags to
        connect news pages.
    </p>

    <p>
        I hunted down and tried Google's own google-sites-export from their Data Liberation Team, but
        could never authenticate correctly.
    </p>

    <p>
        I then feared Iâ€™d need Selenium to trigger the javascript, but then realized that the news pages
        took a single parameter to determine which paginated results to display. Looping would get
        them all.
    </p>

    <div class="code-block">
        for i in $(seq 0 10 120); do<br>
        wget "" \<br>
        "-Onews.$i"<br>
        done
    </div>

    <p>
        After getting the first one, I saw a pattern to match each news stories' relative paths. Then
        extracted out all those paths.
    </p>

    <div class="code-block">
        grep -E -h -o "/a/freeitathens.org/foo/news/[a-z0-9\-]+/" news.* |<br>
        sort -u > news_links
    </div>

    <p>
        Once I had all the paths, it was easy to get wget to fetch them all.
    </p>

    <div class="code-block">
        wget -i news_links -B https://sites.google.com
    </div>

    <p>
        Since I found zero guides online, I tried writing up a simple script from the above, and am
        detailing it here.
    </p>
</body>
</html>