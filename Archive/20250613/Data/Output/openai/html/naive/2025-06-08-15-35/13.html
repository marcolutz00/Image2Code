<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Export News</title>
    <style>
        body {
            font-family: 'Helvetica Neue', Arial, sans-serif;
            margin: 50px;
            line-height: 1.5;
            color: #444;
        }
        h1 {
            font-size: 36px;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .subtitle {
            font-style: italic;
            color: #888;
            font-size: 14px;
            margin-bottom: 25px;
        }
        .header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 18px;
        }
        blockquote {
            background-color: #f5f5f5;
            padding: 15px;
            margin: 20px 0;
            font-family: 'Courier New', Courier, monospace;
            font-size: 16px;
            border-left: 5px solid #ddd;
        }
        a {
            color: #06c;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .code {
            font-family: 'Courier New', Courier, monospace;
            background-color: #f5f5f5;
            padding: 10px;
            display: block;
            margin: 20px 0;
            border-left: 5px solid #ddd;
        }
        p {
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <div class="header">
        <span>Polibyte</span>
        <span>More Info</span>
    </div>
    <h1>Export news from google sites</h1>
    <p class="subtitle">Apr 27, 2012<br>One min of reading</p>
    <p>
        I've put online a quick code snippet, <a href="#">export_google_site_news</a>, to my main repository located on github.
    </p>
    <p>
        To illustrate, for pulling the news posts from <a href="#">https://sites.google.com/a/medinacommunityband.org/www/announcements</a>, you can call:
    </p>
    <blockquote>
        export_google_site_news \<br>
        https://sites.google.com/a/medinacommunityband.org/www \<br>
        announcements
    </blockquote>
    <h2>Genesis of This</h2>
    <p>
        When Free It Athens migrated their site away from Google Sites over to Drupal, they went fresh, losing all the previous content. I just realized that news data on the old site was valuable historical content, and I hadn't saved it.
    </p>
    <p>Initially, I gave recursive wget a whirl.</p>
    <blockquote>
        wget -r --no-parent --no-clobber \<br>
        ""
    </blockquote>
    <p>
        This just flat failed as Google made the mistake of using javascript rather than anchor tags to connect news pages.
    </p>
    <p>
        I hunted down and tried Google's own google-sites-export from their Data Liberation Team, but could never authenticate correctly.
    </p>
    <p>
        I then feared I'd need Selenium to trigger the javascript, but then realized that the news pages took a single parameter to determine which paginated results to display. Looping would get them all.
    </p>
    <blockquote>
        for i in $(seq 0 10 120); do<br>
        wget "" \<br>
        "-Onews.$i"<br>
        done
    </blockquote>
    <p>
        After getting the first one, I saw a pattern to match each news stories' relative paths. Then extracted out all those paths.
    </p>
    <blockquote>
        grep -E -h -o "/a/freeitathens.org/foo/news/[a-z0-9\-_]+" news.* | <br>
        sort -u > news_links
    </blockquote>
    <p>
        Once I had all the paths, it was easy to get wget to fetch them all.
    </p>
    <blockquote>
        wget -i news_links -B https://sites.google.com
    </blockquote>
    <p>
        Since I found zero guides online, I tried writing up a simple script from the above, and am detailing it here.
    </p>
</body>
</html>